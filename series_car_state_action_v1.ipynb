{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "series_car_state_action_v1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominique-nshimyimana/Car-State/blob/master/series_car_state_action_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nPDc8yQtVxk4"
      },
      "source": [
        "#Car State-Action Prection \n",
        "#Colab: TensorFlow and GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ks9AkkCK98M",
        "colab_type": "code",
        "outputId": "2d6816c9-d2f2-4a0d-8492-4fe2e94db305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NeWVBhf1VxlH",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "outputId": "5a7ba494-ef35-4859-88f9-9047fc59dfe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "mounted = '/drive'\n",
        "drive.mount(mounted)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKQaNEw6OKZn",
        "colab_type": "text"
      },
      "source": [
        "# NN state Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQXBfd9dOgPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "\n",
        "class NeuralDynamics(Model):\n",
        "\n",
        "    def __init__(self, input_size, out_size, training=False):\n",
        "\n",
        "        super(NeuralDynamics, self).__init__()\n",
        "\n",
        "        self.training = training\n",
        "        self.out_size = out_size\n",
        "        if type(input_size) is tuple:\n",
        "          self.state_size = input_size[0]\n",
        "          self.action_size = input_size[1]\n",
        "        else:\n",
        "          self.state_size = input_size\n",
        "          self.action_size = out_size\n",
        "\n",
        "        self.layer1 = Dense(300, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "        self.layer2 = Dense(300, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "\n",
        "        self.layer_state1a = Dense(256, activation=tf.nn.relu)\n",
        "\n",
        "        self.layer_state1 = Dense(128, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "\n",
        "        self.layer_state1b = Dense(64, activation=tf.nn.relu)\n",
        "        self.layer_state1c = Dense(32, activation=tf.nn.relu)\n",
        "\n",
        "        self.layer_state2 = Dense(self.out_size, kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "\n",
        "        self.dropout = Dropout(rate=0.2)\n",
        "\n",
        "        self.flatten = Flatten()\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "\n",
        "        #state, action = inputs\n",
        "        #if type(self.input_size) is tuple and self.state_size[0] != state.shape[0]:\n",
        "        #  missing_zeros = self.state_size[0]-state.shape[0]\n",
        "        #  paddings = tf.constant([[missing_zeros, 0], [0, 0]])\n",
        "        #  state = tf.pad(state, paddings, \"CONSTANT\")\n",
        "\n",
        "        x = inputs  # f.concat((state, action), axis=1)\n",
        "        x = self.layer1(x)\n",
        "        if self.training:\n",
        "            x = self.dropout(x)\n",
        "        x = self.layer2(x)\n",
        "        if self.training:\n",
        "            x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.layer_state1a(x)\n",
        "\n",
        "        x = self.layer_state1(x)\n",
        "        if self.training:\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = self.layer_state1b(x)\n",
        "        x = self.layer_state1c(x)\n",
        "        \n",
        "        state = self.layer_state2(x)\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNXEqk8av9as",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NbVLTb8v7qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dat from folder\n",
        "# CSV form: Dataset\n",
        "# Timestamp, x, y, yaw, xvel, yvel, omega, accel, brake, steering\n",
        "def load_states_actions(data_dir, cutoff_beginning = 300, cutoff_end = 1000, norm=True):\n",
        "  data_files = [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) and \".directory\" not in f]\n",
        "\n",
        "  xs_states = []\n",
        "  xs_actions = []\n",
        "  ys = []\n",
        "\n",
        "  for f in data_files:\n",
        "      print(f)\n",
        "      data = np.loadtxt(f, delimiter=', ', skiprows=1, dtype=np.float32)[cutoff_beginning:-cutoff_end, :]\n",
        "      x_states = [data[i, 1:-3] for i in range(len(data))]\n",
        "      x_actions = [data[i, -3:] for i in range(len(data))]\n",
        "      y = x_states[1:]\n",
        "      x_states, x_actions = x_states[:-1], x_actions[:-1]\n",
        "      xs_states += x_states\n",
        "      xs_actions += x_actions\n",
        "\n",
        "  xs_states = np.vstack(xs_states)\n",
        "  xs_actions = np.vstack(xs_actions)\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  xs_states = scaler.fit_transform(xs_states)\n",
        "  xs_actions = scaler.fit_transform(xs_actions)\n",
        "  return xs_states, xs_actions\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "# State(s) at a given time t (or time series until t) and Y is the state at the next time (t + 1).\n",
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\tdataX.append(np.squeeze(dataset[i:(i+look_back)])) #dataset[i:(i+look_back), 0]\n",
        "\t\tdataY.append(np.expand_dims(dataset[i + look_back], axis=0)) #dataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        "\n",
        "def takeSlice(arr, fr, to, name):\n",
        "    \n",
        "    result = arr[:,fr:to,:]\n",
        "    print(name + \": start at \" + str(fr) + \" - shape: \" + str(result.shape))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdvuJSI_sSPl",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgouF-QisSxk",
        "colab_type": "code",
        "outputId": "66387916-aa60-4977-8a75-7640dd3a7616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load Data\n",
        "data_dir = \"/drive/My Drive/neuronyte_logging\"\n",
        "xs_states, xs_actions = load_states_actions(data_dir=data_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/drive/My Drive/neuronyte_logging/NeuroNyte_1585748620.316643\n",
            "/drive/My Drive/neuronyte_logging/NeuroNyte_1585745385.311904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agA_R0amu-Lp",
        "colab_type": "text"
      },
      "source": [
        "### Preparre and Look at Data ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev89--YiuyLs",
        "colab_type": "code",
        "outputId": "d9bdd660-109e-4388-b835-87759238a2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# Split data\n",
        "x_states_train, x_states_test, x_actions_train, x_actions_test = train_test_split(xs_states, xs_actions, test_size=0.10)\n",
        "\n",
        "# How many steps/state in back from t and # How many steps/state in future/forward from t\n",
        "look_back = 10\n",
        "look_forward = 1\n",
        "\n",
        "# reshape into X=t and Y=t+1 for states\n",
        "x_states_train, y_train = create_dataset(x_states_train, look_back)\n",
        "x_states_test, y_test = create_dataset(x_states_test, look_back)\n",
        "\n",
        "# Visualize X=t and Y=t+1\n",
        "t = 3\n",
        "print(y_test[t])\n",
        "print(x_states_test[t+1])\n",
        "print(y_test.shape, y_train.shape)\n",
        "XS_shape, XA_shape, y_shape = x_states_train.shape, x_actions_train.shape, y_train.shape\n",
        "#X = np.array(x_states_train).reshape(XS_shape[0], look_back, XS_shape[-1])\n",
        "#Y = np.array(y_train).reshape(y_shape[0], look_forward, y_shape[-1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5276035  0.45216864 0.5702387  0.555199   0.62312835 0.50016236]]\n",
            "[[0.77648085 0.81285197 0.09078854 0.29369906 0.16058719 0.5005165 ]\n",
            " [0.91787237 0.9681816  0.8643869  0.80523497 0.3466267  0.4992078 ]\n",
            " [0.31193125 0.04743177 0.749698   0.96927243 0.5259143  0.4994809 ]\n",
            " [0.26879603 0.6833418  0.6272962  0.5756756  0.5737585  0.49997318]\n",
            " [0.06498486 0.47037116 0.99659884 0.51514816 0.14767575 0.49993768]\n",
            " [0.3878985  0.28852874 0.2597765  0.24750796 0.51562715 0.49997196]\n",
            " [0.18227232 0.07203329 0.77134943 0.73060024 0.43897957 0.50014406]\n",
            " [0.35233432 0.5868572  0.09986043 0.36935642 0.31492844 0.4993997 ]\n",
            " [0.96108305 0.8933344  0.9468675  0.5670629  0.29988182 0.49965787]\n",
            " [0.5276035  0.45216864 0.5702387  0.555199   0.62312835 0.50016236]]\n",
            "(105332, 1, 6) (948071, 1, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHG-kUgxvoZD",
        "colab_type": "text"
      },
      "source": [
        "# Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ur1DL7vljj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsize = 2\n",
        "decay = ExponentialDecay(0.0004, 20000, 0.99)\n",
        "cosineDecay = tf.keras.experimental.CosineDecayRestarts(0.0004, 30, t_mul=2.0, m_mul=1.0, alpha=0.00001)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=cosineDecay)\n",
        "model = NeuralDynamics((look_back, 6),out_size=6, training=True)\n",
        "EPOCHS = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mCDvJ1evPe2",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS5aNB28pkbW",
        "colab_type": "code",
        "outputId": "54d7e64b-3cfa-4b24-bb51-88ff10f25c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#print(x_states_train.shape, x_actions_train.shape, y_train.shape)\n",
        "#np.array(y_test).reshape(y_test.shape[0], 1, y_test.shape[-1])\n",
        "print('X: ', x_states_test.shape, 'Y: ', y_test.shape)\n",
        "\n",
        "# checkpoint\n",
        "'''\n",
        "filepath=join(mounted, \"My Drive/NeuralModel/lstm_car_state/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\")\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "# Fit the model\n",
        "history = model.fit(X, Y, epochs=EPOCHS, validation_split=0.2, verbose=1, batch_size=20000, callbacks=callbacks_list)\n",
        "'''\n",
        "#history = model.fit(X, Y, epochs=EPOCHS, validation_split=0.2, verbose=1, batch_size=batchsize)\n",
        "\n",
        "model.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
        "history = model.fit(x_states_test, y_test, epochs=EPOCHS, validation_split=0.3, verbose=1, batch_size=batchsize, shuffle = False)\n",
        "\n",
        "model.save(join(mounted, 'My Drive/NeuralModel/lstm_car_state/seriesv1'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:  (105332, 10, 6) Y:  (105332, 1, 6)\n",
            "Epoch 1/200\n",
            "9217/9217 [==============================] - 65s 7ms/step - loss: 11.7780 - val_loss: 0.5793\n",
            "Epoch 2/200\n",
            "9213/9217 [============================>.] - ETA: 0s - loss: 0.3583"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm4Kgzn-0RUh",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri_jQRJ10Qcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " xs_shape, xa_shape, yt_shape = x_states_test.shape, x_actions_test.shape, y_test.shape\n",
        "X = np.array(x_states_test).reshape(xs_shape[0], look_back, xs_shape[-1])\n",
        "Y = np.array(y_test).reshape(yt_shape[0], look_forward, yt_shape[-1])\n",
        "\n",
        "print('Test(xs, sa, y): ', x_states_test.shape, x_actions_test.shape, y_test.shape)\n",
        "#result = model.predict((x_states_test, x_actions_test))\n",
        "result = model.predict(x_states_test)\n",
        "print('Result: ', result.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m9omgdHTL4D",
        "colab_type": "text"
      },
      "source": [
        "# Visualization of result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK9qWgmrTgVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_test.shape, result.shape)\n",
        "xs_states_true = y_test[:,:,0:2] # np.squeeze(x_states_test[:,:,0:2], axis=0)\n",
        "xs_states_pred = result[:,0:2] #  np.squeeze(result[:,:,0:2], axis=0)\n",
        "print(xs_states_true.shape, xs_states_pred.shape)\n",
        "xs_states_true = xs_states_true.reshape(xs_states_true.shape[0], xs_states_true.shape[2])\n",
        "#xs_states_pred = xs_states_pred.reshape(xs_states_pred.shape[0], xs_states_pred.shape[2])\n",
        "\n",
        "begin, fin = 85000, 85050 # Test constrain due to visualization limit\n",
        "xs_states_true = xs_states_true[begin:fin:1]\n",
        "xs_states_pred = xs_states_pred[begin:fin:1]\n",
        "\n",
        "\n",
        "fig,ax = plt.subplots(1,1,figsize=(16,16))\n",
        "ax.plot(*zip(*xs_states_true), 'r')\n",
        "ax.plot(*zip(*xs_states_pred),'b')\n",
        "plt.xlabel('x pos')\n",
        "plt.ylabel('y pos')\n",
        "plt.suptitle(\"yy pasition as one feature\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}