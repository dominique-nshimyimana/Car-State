{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "series_car_state_action_v1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominique-nshimyimana/Car-State/blob/master/series_car_state_action_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nPDc8yQtVxk4"
      },
      "source": [
        "#Car State-Action Prection \n",
        "#Colab: TensorFlow and GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ks9AkkCK98M",
        "colab_type": "code",
        "outputId": "439c1a0b-64e7-4d68-8718-e9ebeb4d142b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NeWVBhf1VxlH",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "outputId": "5cf524ea-37fe-4c62-a1a8-31d2ab3d9573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "mounted = '/drive'\n",
        "drive.mount(mounted)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKQaNEw6OKZn",
        "colab_type": "text"
      },
      "source": [
        "# NN state Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQXBfd9dOgPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "class NeuralDynamics(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, state_size, action_size):\n",
        "\n",
        "        super(NeuralDynamics, self).__init__()\n",
        "\n",
        "        self.training_counter = 0\n",
        "\n",
        "        if type(state_size) is tuple:\n",
        "          self.state_size = state_size\n",
        "          self.action_size = action_size\n",
        "          self.out_size = state_size[1]\n",
        "        else:\n",
        "          self.state_size = state_size\n",
        "          self.action_size = action_size\n",
        "          self.out_size = state_size\n",
        "\n",
        "        self.layer1 = tf.keras.layers.Dense(300, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=0.5)\n",
        "        self.layer2 = tf.keras.layers.Dense(300, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "\n",
        "        self.layer_state1 = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "        self.layer_state2 = tf.keras.layers.Dense(self.out_size, kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "\n",
        "        self.known_inputs = False\n",
        "        self.training_step = 0\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "\n",
        "        state, action = inputs\n",
        "        if type(self.state_size) is tuple and self.state_size[0] != state.shape[0]:\n",
        "          missing_zeros = self.state_size[0]-state.shape[0]\n",
        "          paddings = tf.constant([[missing_zeros, 0], [0, 0]])\n",
        "          state = tf.pad(state, paddings, \"CONSTANT\")\n",
        "\n",
        "        x = tf.concat((state, action), axis=1)\n",
        "        x = self.layer1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer_state1(x)\n",
        "        x = self.dropout(x)\n",
        "        state = self.layer_state2(x)\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNXEqk8av9as",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NbVLTb8v7qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dat from folder\n",
        "# CSV form: Dataset\n",
        "# Timestamp, x, y, yaw, xvel, yvel, omega, accel, brake, steering\n",
        "def load_states_actions(data_dir, cutoff_beginning = 300, cutoff_end = 1000, norm=True):\n",
        "  data_files = [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) and \".directory\" not in f]\n",
        "\n",
        "  xs_states = []\n",
        "  xs_actions = []\n",
        "  ys = []\n",
        "\n",
        "  for f in data_files:\n",
        "      print(f)\n",
        "      data = np.loadtxt(f, delimiter=', ', skiprows=1, dtype=np.float32)[cutoff_beginning:-cutoff_end, :]\n",
        "      x_states = [data[i, 1:-3] for i in range(len(data))]\n",
        "      x_actions = [data[i, -3:] for i in range(len(data))]\n",
        "      y = x_states[1:]\n",
        "      x_states, x_actions = x_states[:-1], x_actions[:-1]\n",
        "      xs_states += x_states\n",
        "      xs_actions += x_actions\n",
        "\n",
        "  xs_states = np.vstack(xs_states)\n",
        "  xs_actions = np.vstack(xs_actions)\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  xs_states = scaler.fit_transform(xs_states)\n",
        "  xs_actions = scaler.fit_transform(xs_actions)\n",
        "  return xs_states, xs_actions\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "# State(s) at a given time t (or time series until t) and Y is the state at the next time (t + 1).\n",
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\tdataX.append(np.squeeze(dataset[i:(i+look_back)])) #dataset[i:(i+look_back), 0]\n",
        "\t\tdataY.append(dataset[i + look_back]) #dataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        "\n",
        "def takeSlice(arr, fr, to, name):\n",
        "    \n",
        "    result = arr[:,fr:to,:]\n",
        "    print(name + \": start at \" + str(fr) + \" - shape: \" + str(result.shape))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdvuJSI_sSPl",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgouF-QisSxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7d709937-f2ec-44a3-d9e9-4ae27a2efab1"
      },
      "source": [
        "# Load Data\n",
        "data_dir = \"/drive/My Drive/neuronyte_logging\"\n",
        "xs_states, xs_actions = load_states_actions(data_dir=data_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/drive/My Drive/neuronyte_logging/NeuroNyte_1585748620.316643\n",
            "/drive/My Drive/neuronyte_logging/NeuroNyte_1585745385.311904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agA_R0amu-Lp",
        "colab_type": "text"
      },
      "source": [
        "### Preparre and Look at Data ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev89--YiuyLs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "cb5b87f2-d20e-4f69-c001-f3dbecc8d149"
      },
      "source": [
        "# Split data\n",
        "x_states_train, x_states_test, x_actions_train, x_actions_test = train_test_split(xs_states, xs_actions, test_size=0.10)\n",
        "\n",
        "# How many steps/state in back from t and # How many steps/state in future/forward from t\n",
        "look_back = 10\n",
        "look_forward = 1\n",
        "\n",
        "# reshape into X=t and Y=t+1 for states\n",
        "x_states_train, y_train = create_dataset(x_states_train, look_back)\n",
        "x_states_test, y_test = create_dataset(x_states_test, look_back)\n",
        "\n",
        "# Visualize X=t and Y=t+1\n",
        "t = 3\n",
        "print(y_test[t])\n",
        "print(x_states_test[t+1])\n",
        "\n",
        "XS_shape, XA_shape, y_shape = x_states_train.shape, x_actions_train.shape, y_train.shape\n",
        "X = np.array(x_states_train).reshape(XS_shape[0], look_back, XS_shape[-1])\n",
        "Y = np.array(y_train).reshape(y_shape[0], look_forward, y_shape[-1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.98198146 0.66104215 0.5010233  0.50080323 0.9988941  0.49995062]\n",
            "[[0.67504954 0.5637433  0.1148226  0.33502385 0.32550812 0.5007954 ]\n",
            " [0.18454403 0.14716876 0.7983072  0.67529637 0.43282956 0.4987799 ]\n",
            " [0.68092257 0.11942458 0.6775433  0.63326335 0.5805489  0.5007576 ]\n",
            " [0.76345164 0.07020801 0.2667284  0.01600128 0.52763337 0.49998266]\n",
            " [0.12828135 0.11987418 0.9549924  0.57600474 0.1490672  0.50053215]\n",
            " [0.2938729  0.5442023  0.077445   0.33114904 0.23117295 0.50036293]\n",
            " [0.9628264  0.40464428 0.5218235  0.56318164 0.98012936 0.499947  ]\n",
            " [0.65710247 0.52185863 0.85714054 0.5062765  0.2780962  0.5013704 ]\n",
            " [0.45695096 0.14309996 0.22922507 0.3351694  0.478396   0.49997175]\n",
            " [0.98198146 0.66104215 0.5010233  0.50080323 0.9988941  0.49995062]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHG-kUgxvoZD",
        "colab_type": "text"
      },
      "source": [
        "# Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ur1DL7vljj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decay=tf.keras.optimizers.schedules.ExponentialDecay(0.0004, 20000, 0.99)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=decay)\n",
        "model = NeuralDynamics((24, 6), 2)\n",
        "EPOCHS = 2\n",
        "batchsize = 2000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mCDvJ1evPe2",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS5aNB28pkbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_states_train.shape, x_actions_train.shape, y_train.shape)\n",
        "model.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "# checkpoint\n",
        "'''\n",
        "filepath=join(mounted, \"My Drive/NeuralModel/lstm_car_state/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\")\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "# Fit the model\n",
        "history = model.fit(X, Y, epochs=EPOCHS, validation_split=0.2, verbose=1, batch_size=20000, callbacks=callbacks_list)\n",
        "'''\n",
        "\n",
        "history = model.fit(X, Y, epochs=EPOCHS, validation_split=0.2, verbose=1, batch_size=batchsize)\n",
        "model.save(join(mounted, 'My Drive/NeuralModel/lstm_car_state/lstm_fin.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm4Kgzn-0RUh",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri_jQRJ10Qcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " xs_shape, xa_shape, yt_shape = x_states_test.shape, x_actions_test.shape, y_test.shape\n",
        "X = np.array(x_states_test).reshape(xs_shape[0], look_back, xs_shape[-1])\n",
        "Y = np.array(y_test).reshape(yt_shape[0], look_forward, yt_shape[-1])\n",
        "\n",
        "print('Test(xs, sa, y): ', x_states_test.shape, x_actions_test.shape, y_test.shape)\n",
        "result = model.predict((x_states_test, x_actions_test))\n",
        "print('Result: ', result.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m9omgdHTL4D",
        "colab_type": "text"
      },
      "source": [
        "# Visualization of result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK9qWgmrTgVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs_states_inpt = np.squeeze(x_states_test[:,:,0:2], axis=0)\n",
        "xs_states_pred = np.squeeze(result[:,:,0:2], axis=0)\n",
        "\n",
        "fig,ax = plt.subplots(1,1,figsize=(16,16))\n",
        "ax.plot(*zip(*xs_states_inpt), 'r')\n",
        "ax.plot(*zip(*xs_states_pred),'b')\n",
        "plt.xlabel('x pos')\n",
        "plt.ylabel('y pos')\n",
        "plt.suptitle(\"yy pasition as one feature\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}